
# ðŸ“— ë¹„íŠ¸ì½”ì¸ ìžë™ë§¤ë§¤ í”„ë¡œê·¸ëž¨ ìƒì„¸ êµ¬í˜„ ê°€ì´ë“œ

---

## âœ… 1. ê°•í™”í•™ìŠµ ì„¸ë¶€ êµ¬í˜„ë°©ë²•

### ðŸ“Œ ê°•í™”í•™ìŠµ ê°œë… ì •ì˜
- **ìƒíƒœ(State)**:
  - ì‹œìž¥ ìƒíƒœ(ìƒìŠ¹ìž¥, í•˜ë½ìž¥, íš¡ë³´ìž¥), RSI, ATR, ê³µí¬&íƒìš• ì§€ìˆ˜, ë³´ìœ  í¬ì§€ì…˜ ìƒíƒœ
- **í–‰ë™(Action)**:
  - ì†ì ˆ ë¹„ìœ¨(-5%, -7%, -10%), í¬ì§€ì…˜ í¬ê¸°(10~30%)
- **ë³´ìƒ(Reward)**:
  - ëˆ„ì  ìˆ˜ìµë¥ , ìƒ¤í”„ ë¹„ìœ¨, ìµœëŒ€ ë‚™í­(MDD)

### ðŸ“Œ ì¶”ì²œ ê°•í™”í•™ìŠµ ì•Œê³ ë¦¬ì¦˜
- **PPO(Proximal Policy Optimization)** ì¶”ì²œ

### ðŸ“Œ ê°„ëžµ ì½”ë“œ ì˜ˆì‹œ
```python
class Environment:
    def __init__(self):
        self.market_state = None
        self.position = None
        self.rsi = None
        self.fear_greed_index = None
        
    def get_state(self):
        return (self.market_state, self.position, self.rsi, self.fear_greed_index)

    def step(self, action):
        next_state = self.get_state()
        reward = calculate_reward(...)
        return next_state, reward

agent = PPO(env=Environment())
agent.train(episodes=1000)
```

---

## âœ… 2. ê¸°ìˆ ì  ì§€í‘œ ìƒì„¸ ê³„ì‚°ë²•

### ðŸ“Œ EMA
```python
df['EMA7'] = df['close'].ewm(span=7, adjust=False).mean()
df['EMA21'] = df['close'].ewm(span=21, adjust=False).mean()
```

### ðŸ“Œ MACD
```python
exp1 = df['close'].ewm(span=12, adjust=False).mean()
exp2 = df['close'].ewm(span=26, adjust=False).mean()
df['MACD'] = exp1 - exp2
df['Signal'] = df['MACD'].ewm(span=9, adjust=False).mean()
```

### ðŸ“Œ RSI
```python
delta = df['close'].diff()
gain = (delta.where(delta > 0, 0)).rolling(14).mean()
loss = (-delta.where(delta < 0, 0)).rolling(14).mean()
rs = gain / loss
df['RSI'] = 100 - (100 / (1 + rs))
```

### ðŸ“Œ ë³¼ë¦°ì € ë°´ë“œ
```python
df['MB'] = df['close'].rolling(window=20).mean()
df['UB'] = df['MB'] + 1.5 * df['close'].rolling(20).std()
df['LB'] = df['MB'] - 1.5 * df['close'].rolling(20).std()
```

### ðŸ“Œ ê±°ëž˜ëŸ‰ ê¸‰ì¦(Z-score)
```python
df['volume_zscore'] = (df['volume'] - df['volume'].rolling(20).mean()) / df['volume'].rolling(20).std()
```

---

## âœ… 3. GPT API ì—°ë™ ìƒì„¸ ì½”ë“œ ì˜ˆì‹œ

```python
import openai

openai.api_key = "YOUR_API_KEY"

prompt = """
ì‹œìž¥í˜„í™©: ìµœê·¼ 24ì‹œê°„ -2.5%, íš¡ë³´ìž¥  
ë³¼ë¦°ì €ë°´ë“œ: í•˜ë‹¨ 2.0Ïƒ ëŒíŒŒ  
RSI: 22 (ê¸‰ê²©í•˜ë½)  
ê±°ëž˜ëŸ‰ Z-score: 3.6  
ê³µí¬íƒìš•ì§€ìˆ˜: 18(ê¸‰ë½)

1. í˜„ìƒí™© ë¶„ì„
2. ëŒ€ì‘ ì „ëžµ ì¶”ì²œ
3. ì‹ ë¢°ë„(%)
4. ìµœì†Œ ë°˜ì„±ì˜ê²¬
"""

response = openai.ChatCompletion.create(
  model="gpt-4o",
  messages=[{"role": "user", "content": prompt}]
)

print(response.choices[0].message.content)
```

---

## âœ… 4. ë°ì´í„° ë…¸ì´ì¦ˆ ì¶”ê°€ ì˜ˆì‹œ ì½”ë“œ

```python
import numpy as np

def add_noise(data, noise_level=0.02):
    noise = np.random.normal(0, noise_level, data.shape)
    return data + data * noise

df['close_noisy'] = add_noise(df['close'])
```

---

## âœ… 5. ë°±í…ŒìŠ¤íŠ¸ í™˜ê²½ ì´ˆê¸°í™” ì˜ˆì‹œ ì½”ë“œ

```python
import numpy as np
import random

def reset_environment(seed=42):
    np.random.seed(seed)
    random.seed(seed)
    df = pd.read_csv('btc_data.csv')
    return df

df = reset_environment()
```

---

## âœ… 6. ì˜ˆì™¸ì²˜ë¦¬ ì˜ˆì‹œ ì½”ë“œ

```python
import time

for attempt in range(3):
    try:
        data = api.get_market_data()
        break
    except Exception as e:
        print(f'API í˜¸ì¶œ ì‹¤íŒ¨({attempt+1}/3): {e}')
        time.sleep(5)
else:
    print('API ì‹¤íŒ¨: ë‹¤ìŒ ì£¼ê¸°ë¡œ ë¯¸ë£¸.')
```
